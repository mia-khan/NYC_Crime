{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning: Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv\n",
    "pop_df = pd.read_csv(\"New_York_City_Population_by_Borough__1950_-_2040.csv\")\n",
    "pop_df.columns = pop_df.columns.str.strip()  # delete any extra spaces in col name\n",
    "\n",
    "# only total population\n",
    "pop_2020_df = pop_df[pop_df[\"Age Group\"] == \"Total Population\"][[\"Borough\", \"2020\"]].copy()\n",
    "\n",
    "# clean up names\n",
    "pop_2020_df[\"Borough\"] = pop_2020_df[\"Borough\"].str.strip().str.title()\n",
    "\n",
    "# drop total\n",
    "pop_2020_df = pop_2020_df[pop_2020_df[\"Borough\"] != \"Nyc Total\"]\n",
    "\n",
    "# dict\n",
    "borough_pop = pop_2020_df.set_index(\"Borough\")[\"2020\"].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file: nyc-park-crime-stats-q1-2024.xlsx with error name 'numeric_columns' is not defined\n",
      "Error loading file: nyc-park-crime-stats-q2-2024.xlsx with error name 'numeric_columns' is not defined\n",
      "Error loading file: nyc-park-crime-stats-q3-2024.xlsx with error name 'numeric_columns' is not defined\n",
      "Error loading file: nyc-park-crime-stats-q4-2024.xlsx with error name 'numeric_columns' is not defined\n",
      "Error loading file: nyc-park-crime-stats-q1-2023.xlsx with error name 'numeric_columns' is not defined\n",
      "Error loading file: nyc-park-crime-stats-q2-2023.xlsx with error name 'numeric_columns' is not defined\n",
      "Error loading file: nyc-park-crime-stats-q3-2023.xlsx with error name 'numeric_columns' is not defined\n",
      "Error loading file: nyc-park-crime-stats-q4-2023.xlsx with error name 'numeric_columns' is not defined\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError loading file: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m fp \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with error \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m---> 63\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(list_of_dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     65\u001b[0m combined_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBOROUGH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m combined_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBOROUGH\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mtitle()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Compute per capita crime\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    385\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[1;32m    386\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m    387\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[1;32m    388\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[1;32m    389\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[1;32m    390\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[1;32m    391\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "def read_all_sheets_from_excel(filepath):\n",
    "    \"\"\"Read all sheets from an Excel file into a dictionary of dataframes\"\"\"\n",
    "    xl = pd.ExcelFile(filepath)\n",
    "    return {sheet_name: xl.parse(sheet_name) for sheet_name in xl.sheet_names}\n",
    "\n",
    "filepaths = {\n",
    "    '2024_Q1': 'nyc-park-crime-stats-q1-2024.xlsx',\n",
    "    '2024_Q2': 'nyc-park-crime-stats-q2-2024.xlsx',\n",
    "    '2024_Q3': 'nyc-park-crime-stats-q3-2024.xlsx',\n",
    "    '2024_Q4': 'nyc-park-crime-stats-q4-2024.xlsx',\n",
    "    '2023_Q1': 'nyc-park-crime-stats-q1-2023.xlsx',\n",
    "    '2023_Q2': 'nyc-park-crime-stats-q2-2023.xlsx',\n",
    "    '2023_Q3': 'nyc-park-crime-stats-q3-2023.xlsx',\n",
    "    '2023_Q4': 'nyc-park-crime-stats-q4-2023.xlsx'\n",
    "}\n",
    "\n",
    "list_of_dfs = []\n",
    "\n",
    "for key, fp in filepaths.items():\n",
    "    try:\n",
    "        all_sheets = read_all_sheets_from_excel(fp)\n",
    "        sheet_name = list(all_sheets.keys())[0]\n",
    "        df = all_sheets[sheet_name]\n",
    "\n",
    "        df = all_sheets[sheet_name]\n",
    "\n",
    "        # Clean and preserve original header row\n",
    "        df = df.drop(index=1).reset_index(drop=True)  # Drop only the second row if it's garbage\n",
    "\n",
    "        # Ensure column names are clean and valid\n",
    "        df.columns = df.columns.astype(str).str.strip()\n",
    "\n",
    "        # Drop duplicate columns, just in case\n",
    "        df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "        # Fix borough names\n",
    "        df[\"BOROUGH\"] = df[\"BOROUGH\"].str.strip().str.title()\n",
    "\n",
    "        # Split 'Brooklyn/Queens' rows in half\n",
    "        if \"Brooklyn/Queens\" in df[\"BOROUGH\"].values:\n",
    "            bq_rows = df[df[\"BOROUGH\"] == \"Brooklyn/Queens\"]\n",
    "            bq_brooklyn = bq_rows.copy()\n",
    "            bq_brooklyn[\"BOROUGH\"] = \"Brooklyn\"\n",
    "            bq_brooklyn[numeric_columns] = bq_brooklyn[numeric_columns] / 2\n",
    "\n",
    "            bq_queens = bq_rows.copy()\n",
    "            bq_queens[\"BOROUGH\"] = \"Queens\"\n",
    "            bq_queens[numeric_columns] = bq_queens[numeric_columns] / 2\n",
    "\n",
    "            df = df[df[\"BOROUGH\"] != \"Brooklyn/Queens\"]\n",
    "            df = pd.concat([df, bq_brooklyn, bq_queens], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        df['quarter'] = key\n",
    "        list_of_dfs.append(df)\n",
    "        print('Loaded and cleaned file: ' + fp + ' as ' + key)\n",
    "        print(\"Cleaned DataFrame Head:\")\n",
    "        print(df.head())\n",
    "    except Exception as e:\n",
    "        print('Error loading file: ' + fp + ' with error ' + str(e))\n",
    "\n",
    "combined_df = pd.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "combined_df[\"BOROUGH\"] = combined_df[\"BOROUGH\"].str.strip().str.title()\n",
    "\n",
    "# Compute per capita crime\n",
    "combined_df[\"Crimes_per_capita\"] = combined_df.apply(\n",
    "    lambda row: (row[\"TOTAL\"] / borough_pop.get(row[\"BOROUGH\"], 1)) * 100000, axis=1\n",
    ")\n",
    "combined_df[\"Crimes_per_capita\"] = combined_df[\"Crimes_per_capita\"].round(8)\n",
    "\n",
    "combined_df.columns = [col.strip() for col in combined_df.columns]\n",
    "\n",
    "numeric_columns = ['SIZE (ACRES)', 'MURDER', 'RAPE', 'ROBBERY', 'FELONY ASSAULT',\n",
    "                   'BURGLARY', 'GRAND LARCENY', 'GRAND LARCENY OF MOTOR VEHICLE', 'TOTAL']\n",
    "for col in numeric_columns:\n",
    "    if col in combined_df.columns:\n",
    "        combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "print('Combined DataFrame head:')\n",
    "print(combined_df.head())\n",
    "\n",
    "# Visualization 1: Bar chart showing crime distribution by borough\n",
    "# crime_by_borough = combined_df.groupby('BOROUGH')['TOTAL'].sum().reset_index()\n",
    "crime_by_borough = combined_df.groupby('BOROUGH')['Crimes_per_capita'].sum().reset_index() # modified\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "# bar_plot = sns.barplot(data=crime_by_borough, x='BOROUGH', y='TOTAL', palette='viridis')\n",
    "bar_plot = sns.barplot(data=crime_by_borough, x='BOROUGH', y='Crimes_per_capita', palette='viridis')  # modified\n",
    "\n",
    "plt.title('2023–2024 Park Crime Rate Per Capita by NYC Borough') \n",
    "plt.xlabel('NYC Borough') \n",
    "plt.ylabel('Crimes per 100,000 Residents')  \n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('pc_crime_distribution_barchart.png')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Stacked bar chart that compares different crime types by borough\n",
    "crime_types = ['MURDER', 'RAPE', 'ROBBERY', 'FELONY ASSAULT', 'BURGLARY', 'GRAND LARCENY',\n",
    "               'GRAND LARCENY OF MOTOR VEHICLE']\n",
    "crime_by_type = combined_df.groupby('BOROUGH')[crime_types].sum()\n",
    "\n",
    "for col in crime_types:\n",
    "    crime_by_type[col] = crime_by_type[col] / crime_by_type.index.map(borough_pop)  # Per capita normalization\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "crime_by_type.plot(kind='bar', stacked=True, figsize=(12, 10), colormap='tab20')\n",
    "plt.title('2023–2024 Breakdown of Park Crime Types Per Capita by Borough') \n",
    "plt.xlabel('NYC Borough') \n",
    "plt.ylabel('Crimes per 100,000 Residents')   \n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Crime Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pc_crime_types_stacked.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Visualization 3: Scatter plot analyzing relationship between park size and crime count\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter_plot = sns.scatterplot(data=combined_df, x='SIZE (ACRES)', y='TOTAL', hue='BOROUGH', palette='deep')\n",
    "plt.title('Relationship Between Park Size and Crime Count')\n",
    "plt.xlabel('Park Size (Acres)')\n",
    "plt.ylabel('Total Crime Count')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pc_parksize_vs_crime.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
